#!/bin/bash

# Configuration for FSDP jobs

## AWS
export AWS_REGION=us-east-1
export ACCOUNT=$(aws sts get-caller-identity --query Account --output text)

## Docker Image
export REGISTRY=${ACCOUNT}.dkr.ecr.${AWS_REGION}.amazonaws.com/
export IMAGE=fsdp
## DOCKERFILE_EXT=nanogpt-sockets|nanogpt-efa|llama2-sockets|llama2-efa
export DOCKERFILE_EXT=nanogpt-sockets
export TAG=":${DOCKERFILE_EXT}"

## FSDP Job
export JOB_NAME=pytorch-fsdp
export RDZV_HOST=etcd
export RDZV_PORT=2379
export NUM_WORKERS=2
export EFA_PER_WORKER=0
export NPROC_PER_WORKER=4
## INSTANCE_TYPE=p4de.24xlarge|p5.48xlarge|g5.12xlarge|g5.2xlarge|g4dn.metal|g4dn.8xlarge|etc.
## We recommend starting with instance type g5.12xlarge. It has 4 NVIDIA A10 GPUs per worker node. The FSDP example can run in a single node or across multiple nodes.
## Cluster configuration Ref: https://github.com/aws-samples/aws-do-eks/blob/main/wd/conf/eksctl/yaml/eks-gpu-fsdp.yaml
export INSTANCE_TYPE=g5.12xlarge
## FI_PROVIDER=sockets|efa
export FI_PROVIDER=sockets

## Model
## Support is available for NanoGPT and Llama2. Only one of the sections below should be uncommented and should match the DOCKERFILE_EXT section above

## NanoGPT
## NanoGPT train command
export CMD="python -m torch.distributed.run --nproc-per-node=$NPROC_PER_WORKER fsdp_train.py"
## MODEL_NAME=10.5M | 124M | 201M | 1B | 1.5B | 20B
export MODEL_NAME="10.5M"


## Llama2
## Register at Huggingface and get a token by visiting: https://huggingface.co/docs/hub/security-tokens, then insert your token here
#export HF_TOKEN="Insert_Your_HuggingfFace_Login_Token_Here"
## Llama2 MODEL_NAME=meta-llama/Llama-2-7b-hf | meta-llama/Llama-2-13b-hf | meta-llama/Llama-2-70b-hf
#export MODEL_NAME=meta-llama/Llama-2-7b-hf
## Llama2 train command
#export CMD="huggingface-cli login --token ${HF_TOKEN} && torchrun --nproc_per_node=${NPROC_PER_WORKER} --nnodes=${NUM_WORKERS} examples/finetuning.py --num_epochs=1 --batch_size_training=3 --use_peft --peft_method lora --pure_bf16 --enable_fsdp --low_cpu_fsdp --model_name $MODEL_NAME --output_dir ."

